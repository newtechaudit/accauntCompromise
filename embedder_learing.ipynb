{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-P8A5wm-i5O"
   },
   "source": [
    "# PyTorch Metric Learning\n",
    "### Example for the MetricLossOnly trainer\n",
    "See the documentation [here](https://kevinmusgrave.github.io/pytorch-metric-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKpRHvy24tV7"
   },
   "source": [
    "## Install the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ZeIGxbbp3W2S",
    "outputId": "4cbced5a-f22d-4a15-b4eb-20177f019ad8"
   },
   "outputs": [],
   "source": [
    "# !pip install -q pytorch-metric-learning\n",
    "# !pip install -q faiss-gpu\n",
    "# !pip install -q umap-learn\n",
    "# !pip install -q pynndescent\n",
    "# !pip install -q record-keeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BfqRRbIw4zYR"
   },
   "source": [
    "## Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "567qnmi7wk_M",
    "outputId": "9c471dc4-9acc-414c-f7e1-0f53d1a5dbe7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:VERSION 0.9.95\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import pairwise\n",
    "from pytorch_metric_learning import losses, miners, samplers, trainers, testers\n",
    "from pytorch_metric_learning.utils import common_functions as c_f\n",
    "from pytorch_metric_learning.utils import common_functions\n",
    "import pytorch_metric_learning.utils.logging_presets as logging_presets\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from cycler import cycler\n",
    "import record_keeper\n",
    "import pytorch_metric_learning\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.info(\"VERSION %s\"%pytorch_metric_learning.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 64\n",
    "retrain = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qxs6EEeR496q"
   },
   "source": [
    "## Simple model def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from img_embedder import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btjxk6zR5Cl6"
   },
   "source": [
    "## Initialize models, optimizers and image transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "4baa6255aedc4c148cfdab9e177a0ab4",
      "1df2d4834302478796ae1403e116e038",
      "cab96c71f5fe49208cfc63ac5f8a5640",
      "49e70e4be7a747ab94d47ba98f3e1c2d",
      "d4c06565e0d44bcab2dd41ee49a72c65",
      "74218a73cf5247c58aaaf1d28319ebf5",
      "13f206dd0b8e422eb8a4c64fcff25faf",
      "f7950c31f11a4287bea7448f0429c4d9"
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "8tzmyFS3wk_R",
    "outputId": "bf24861f-5561-4525-b9c0-0290f2cf5fe6"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set trunk model and replace the softmax layer with an identity function\n",
    "trunk = torchvision.models.resnet50(pretrained=True)\n",
    "trunk.fc = c_f.Identity()\n",
    "trunk = nn.DataParallel(trunk.to(device))\n",
    "\n",
    "print(trunk_output_size, \">\", emb_size)\n",
    "\n",
    "# Set embedder model. This takes in the output of the trunk and outputs 'emb_size' dimensional embeddings\n",
    "trunk_output_size = trunk.fc.in_features\n",
    "embedder = torch.nn.DataParallel(MLP([trunk_output_size, emb_size]).to(device))\n",
    "\n",
    "# Set optimizers\n",
    "trunk_optimizer = torch.optim.Adam(trunk.parameters(), lr=0.00001, weight_decay=0.0001)\n",
    "embedder_optimizer = torch.optim.Adam(embedder.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "\n",
    "norm = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# size = 196\n",
    "size = 128\n",
    "\n",
    "# Set the image transforms\n",
    "train_transform = transforms.Compose([transforms.Resize((size, size)),\n",
    "                                    #transforms.RandomResizedCrop(scale=(0.16, 1), ratio=(0.75, 1.33), size=64),\n",
    "                                    transforms.RandomRotation(degrees=(-30, 30)),\n",
    "                                    transforms.RandomHorizontalFlip(0.5),\n",
    "                                    transforms.RandomVerticalFlip(0.5),                               \n",
    "                                    transforms.ToTensor(),\n",
    "                                    norm])\n",
    "\n",
    "val_transform = transforms.Compose([transforms.Resize((size, size)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Замена softmax на identity function\n",
    "trunk = torchvision.models.resnet50(pretrained=True)\n",
    "trunk.fc = c_f.Identity()\n",
    "trunk = nn.DataParallel(trunk.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf0xgdWS5GqG"
   },
   "source": [
    "## Create the dataset and class-disjoint train/val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "e1d0273ab5c04cb98c6624cca248b6fb",
      "8acb60a00b85468e9ba6aa6a850055d0",
      "5ad047b5550044feb4b36b9af41dd16a",
      "db2c3c30ded64edd94b559e80992b182",
      "34fe0747edb74c829d8ac258ccddf4f2",
      "b754fee1719043ccab48589b78a168de",
      "1827ae60ebe7429b8423872c7efa5ece",
      "27e8026800e74ac2af11a91b160592bd"
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "D-nmnYYAwk_T",
    "outputId": "1b331beb-265c-435d-a729-a6ed1a360ae5"
   },
   "outputs": [],
   "source": [
    "input_path = \"datasets/workers\"\n",
    "\n",
    "original_train = datasets.ImageFolder(os.path.join(input_path, 'train'))\n",
    "original_val = datasets.ImageFolder(os.path.join(input_path, 'validation'))\n",
    "original_test = datasets.ImageFolder(os.path.join(input_path, 'test'))\n",
    "\n",
    "# This will be used to create train and val sets that are class-disjoint\n",
    "class ClassDisjoint(torch.utils.data.Dataset):\n",
    "    def __init__(self, original_train, original_val, train, transform):\n",
    "        if train:\n",
    "            self.data = np.array(original_train.imgs)\n",
    "            self.targets = np.array(original_train.targets)\n",
    "        else:\n",
    "            self.data = np.array(original_val.imgs)\n",
    "            self.targets = np.array(original_val.targets)\n",
    "        self.data = [x[0] for x in self.data.tolist()]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        img = Image.open(img)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "# Class disjoint training and validation set\n",
    "train_dataset = ClassDisjoint(original_train, original_val, True, train_transform)\n",
    "val_dataset = ClassDisjoint(original_train, original_val, False, val_transform)\n",
    "test_dataset = ClassDisjoint(original_train, original_test, False, val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset[10][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r7J817Vs5LNs"
   },
   "source": [
    "## Create the loss, miner, sampler, and package them into dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Kp9AC_4Dwk_V",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set the loss function\n",
    "loss = losses.TripletMarginLoss(margin=0.1)\n",
    "\n",
    "# Set the mining function\n",
    "miner = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "\n",
    "# Set the dataloader sampler\n",
    "sampler = samplers.MPerClassSampler(train_dataset.targets, m=4, length_before_new_iter=len(train_dataset))\n",
    "\n",
    "# Set other training parameters\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "\n",
    "# Package the above stuff into dictionaries.\n",
    "models = {\"trunk\": trunk, \"embedder\": embedder}\n",
    "optimizers = {\"trunk_optimizer\": trunk_optimizer, \"embedder_optimizer\": embedder_optimizer}\n",
    "loss_funcs = {\"metric_loss\": loss}\n",
    "mining_funcs = {\"tuple_miner\": miner}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_folder = \"image_embedder_model_\" + ('small_img', 'large_img')[size > 140] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if retrain:\n",
    "    # Remove logs if you want to train with new parameters\n",
    "    !rm -rf image_embedder_logs/ image_embedder_tensorboard/ {model_folder}/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A9fa1VYD5Yv0"
   },
   "source": [
    "## Create the training and testing hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Vq_Pd7Pd5Xi_",
    "outputId": "a9f89441-1a96-4fe4-9b5b-0e4d43c581a2"
   },
   "outputs": [],
   "source": [
    "record_keeper, _, _ = logging_presets.get_record_keeper(\"image_embedder_logs\", \"image_embedder_tensorboard\")\n",
    "hooks = logging_presets.get_hook_container(record_keeper)\n",
    "dataset_dict = {\"val\": val_dataset}\n",
    "\n",
    "def visualizer_hook(umapper, umap_embeddings, labels, split_name, keyname, *args):\n",
    "    logging.info(\"UMAP plot for the {} split and label set {}\".format(split_name, keyname))\n",
    "    label_set = np.unique(labels)\n",
    "    num_classes = len(label_set)\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    plt.gca().set_prop_cycle(cycler(\"color\", [plt.cm.nipy_spectral(i) for i in np.linspace(0, 0.9, num_classes)]))\n",
    "    for i in range(num_classes):\n",
    "        idx = labels == label_set[i]\n",
    "        plt.plot(umap_embeddings[idx, 0], umap_embeddings[idx, 1], \".\", markersize=1)   \n",
    "    plt.show()\n",
    "\n",
    "# Create the tester\n",
    "tester = testers.GlobalEmbeddingSpaceTester(end_of_testing_hook = hooks.end_of_testing_hook, \n",
    "                                            visualizer = umap.UMAP(), \n",
    "                                            visualizer_hook = visualizer_hook,\n",
    "                                            dataloader_num_workers = 32)\n",
    "\n",
    "end_of_epoch_hook = hooks.end_of_epoch_hook(tester, \n",
    "                                            dataset_dict, \n",
    "                                            model_folder, \n",
    "                                            test_interval = 1,\n",
    "                                            patience = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A0D3Jvxc5iWD"
   },
   "source": [
    "## Create the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DuASrVs-wk_X",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer = trainers.MetricLossOnly(models,\n",
    "                                optimizers,\n",
    "                                batch_size,\n",
    "                                loss_funcs,\n",
    "                                mining_funcs,\n",
    "                                train_dataset,\n",
    "                                sampler=sampler,\n",
    "                                dataloader_num_workers = 32,\n",
    "                                end_of_iteration_hook = hooks.end_of_iteration_hook,\n",
    "                                end_of_epoch_hook = end_of_epoch_hook\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yl_z0VoXIKrk"
   },
   "source": [
    "## Start Tensorboard\n",
    "(Turn off adblock and other shields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "35aR2k0zIK4V"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir example_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gIq7s7jf5ksj"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "WHza2JJHwk_Z",
    "outputId": "90a4d99a-1a9a-4054-9f60-73b6f21531fd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if retrain:\n",
    "    trainer.train(num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved_models = os.path.join(os.getcwd(), model_folder)\n",
    "\n",
    "for _, _, files in os.walk(saved_models): break\n",
    "[file for file in files if file.__contains__('best')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_model = os.path.join(saved_models, [x for x in files if x.__contains__('trunk_best')][0])\n",
    "path_embedder = os.path.join(saved_models, [x for x in files if x.__contains__('embedder_best')][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = ImageEmbedder(path_model, path_embedder, val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Поиск наилучшей границы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "persons = dict()\n",
    "input_path = \"datasets/workers\"\n",
    "\n",
    "for dpath in ['test','train','validation']:\n",
    "    for c, d, f in os.walk(os.path.join(input_path, dpath)):        \n",
    "        for z in f:\n",
    "            person = os.path.basename(c)\n",
    "            filepath = os.path.join(c, z)\n",
    "            i = persons.get(person, list())\n",
    "            i.append([filepath, emb.img2vect(Image.open(filepath))])\n",
    "            persons[person] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "for person, vectors in persons.items():\n",
    "    for vector in vectors:\n",
    "        files.append([person, vector[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec_arr = [x[1] for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cos_sim = pairwise.cosine_similarity(vec_arr, vec_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = []\n",
    "x = 0\n",
    "y = 0\n",
    "for vec1 in tqdm(files):\n",
    "    x = 0\n",
    "    for vec2 in files:\n",
    "        same = vec1[0] == vec2[0]\n",
    "        out.append({'same': int(vec1[0] == vec2[0]), 'cos': cos_sim[x][y]})\n",
    "        x += 1\n",
    "    y += 1\n",
    "out=pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out[(out['same']==1) & (out['cos']!=1)].mean()['cos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out[out['same']==0].mean()['cos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_class = 1\n",
    "img = Image.open(test_dataset.data[main_class])\n",
    "main_vector = emb.img2vect(img)\n",
    "test_embeddings = emb.dataloader2vect(dataloader)[0]\n",
    "l = len(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cos(img1, img2):\n",
    "    if isinstance(img1, Image.Image):\n",
    "        img1 = emb.img2vect(img1)\n",
    "    if isinstance(img2, Image.Image):\n",
    "        img2 = emb.img2vect(img2)\n",
    "    return np.dot(img1, img2) / np.linalg.norm(img1) / np.linalg.norm(img2)\n",
    "    \n",
    "fig = plt.figure(figsize=(20, 3))\n",
    "\n",
    "img90 = img.rotate(90, expand=True)\n",
    "img180 = img.rotate(180, expand=True)\n",
    "img270 = img.rotate(270, expand=True)\n",
    "\n",
    "plt.subplot(1, 5, 1); plt.imshow(img);\n",
    "plt.subplot(1, 5, 2); plt.imshow(img90);\n",
    "plt.subplot(1, 5, 3); plt.imshow(img180);\n",
    "plt.subplot(1, 5, 4); plt.imshow(img270);\n",
    "plt.subplot(1, 5, 5); \n",
    "plt.text(0.1, 0.75, '1.0000000', fontsize=20); \n",
    "plt.text(0.1, 0.55, cos(img, img90), fontsize=20);\n",
    "plt.text(0.1, 0.35, cos(img, img180), fontsize=20);\n",
    "plt.text(0.1, 0.15, cos(img, img270), fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_class = [0, 5, 7, 11, 8][3]\n",
    "img = Image.open(test_dataset.data[main_class])\n",
    "main_vector = emb.img2vect(img)\n",
    "test_embeddings = emb.dataloader2vect(dataloader)[0]\n",
    "l = len(test_embeddings)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,40))\n",
    "treshold = 0.92\n",
    "\n",
    "for i in range(l):\n",
    "    c = cos(main_vector, test_embeddings[i])\n",
    "    plt.subplot(l, 3, i*3+1); plt.imshow(img);\n",
    "    plt.subplot(l, 3, i*3+2); plt.imshow(Image.open(test_dataset.data[i]));\n",
    "    plt.subplot(l, 3, i*3+3);\n",
    "    plt.text(0.2, 0.6, 'схожи' if c > treshold else 'различны', \n",
    "             fontsize=20, color='g' if c > treshold else 'r',);\n",
    "    plt.text(0.05, 0.4, 'коэф.схожести = ' + str(round(c, 3)), fontsize=12);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MetricLossOnly.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch_p36",
   "language": "python",
   "name": "torch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13f206dd0b8e422eb8a4c64fcff25faf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1827ae60ebe7429b8423872c7efa5ece": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1df2d4834302478796ae1403e116e038": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27e8026800e74ac2af11a91b160592bd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34fe0747edb74c829d8ac258ccddf4f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "49e70e4be7a747ab94d47ba98f3e1c2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7950c31f11a4287bea7448f0429c4d9",
      "placeholder": "​",
      "style": "IPY_MODEL_13f206dd0b8e422eb8a4c64fcff25faf",
      "value": " 44.7M/44.7M [00:16&lt;00:00, 2.81MB/s]"
     }
    },
    "4baa6255aedc4c148cfdab9e177a0ab4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cab96c71f5fe49208cfc63ac5f8a5640",
       "IPY_MODEL_49e70e4be7a747ab94d47ba98f3e1c2d"
      ],
      "layout": "IPY_MODEL_1df2d4834302478796ae1403e116e038"
     }
    },
    "5ad047b5550044feb4b36b9af41dd16a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b754fee1719043ccab48589b78a168de",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_34fe0747edb74c829d8ac258ccddf4f2",
      "value": 1
     }
    },
    "74218a73cf5247c58aaaf1d28319ebf5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8acb60a00b85468e9ba6aa6a850055d0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b754fee1719043ccab48589b78a168de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cab96c71f5fe49208cfc63ac5f8a5640": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74218a73cf5247c58aaaf1d28319ebf5",
      "max": 46827520,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4c06565e0d44bcab2dd41ee49a72c65",
      "value": 46827520
     }
    },
    "d4c06565e0d44bcab2dd41ee49a72c65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "db2c3c30ded64edd94b559e80992b182": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27e8026800e74ac2af11a91b160592bd",
      "placeholder": "​",
      "style": "IPY_MODEL_1827ae60ebe7429b8423872c7efa5ece",
      "value": " 169009152/? [00:07&lt;00:00, 23167622.00it/s]"
     }
    },
    "e1d0273ab5c04cb98c6624cca248b6fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5ad047b5550044feb4b36b9af41dd16a",
       "IPY_MODEL_db2c3c30ded64edd94b559e80992b182"
      ],
      "layout": "IPY_MODEL_8acb60a00b85468e9ba6aa6a850055d0"
     }
    },
    "f7950c31f11a4287bea7448f0429c4d9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
